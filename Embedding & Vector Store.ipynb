{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d3413f-4a73-4e56-9395-1e36438614b0",
   "metadata": {},
   "source": [
    "###  Load Text Chunks from a File (Ensure Data Persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7807f7bd-222d-4a30-90c8-284581796db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 29 text chunks from file.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load preprocessed text chunks from a file\n",
    "with open(\"preprocessed_text_chunks.pkl\", \"rb\") as file:\n",
    "    text_chunks = pickle.load(file)\n",
    "\n",
    "print(f\" Loaded {len(text_chunks)} text chunks from file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902e90d-7d3a-4733-ba5d-0b513d26117a",
   "metadata": {},
   "source": [
    "### Load & Initialize the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decd906d-9299-455b-9e9d-4d765ff571dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\RAG_Chatbot\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Small, fast, and effective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4a658-db7d-45a0-9aad-9a4e1bcbe95f",
   "metadata": {},
   "source": [
    "### Convert Text Chunks into Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c06ad9-266e-4a26-b29d-58c3138c4115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generated 29 embeddings with dimension 384\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert text chunks to embeddings\n",
    "chunk_embeddings = embedder.encode(text_chunks)\n",
    "\n",
    "# Convert to NumPy array\n",
    "chunk_embeddings = np.array(chunk_embeddings)\n",
    "\n",
    "print(f\" Generated {chunk_embeddings.shape[0]} embeddings with dimension {chunk_embeddings.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9092064f-0503-4653-b7af-4607451048ad",
   "metadata": {},
   "source": [
    "### Store Embeddings in FAISS (Vector Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0083da4-a402-411e-a4e9-13d12cd5d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stored 29 vectors in FAISS database\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Define embedding dimensions\n",
    "dimension = chunk_embeddings.shape[1]  # Get embedding size\n",
    "\n",
    "# Initialize FAISS index\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 (Euclidean) distance for similarity search\n",
    "\n",
    "# Add embeddings to FAISS index\n",
    "index.add(chunk_embeddings)\n",
    "\n",
    "print(f\" Stored {index.ntotal} vectors in FAISS database\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c9b9e-8918-42d6-8875-5e699a1670a8",
   "metadata": {},
   "source": [
    "### Implement Retrieval Function\n",
    "Now, we search FAISS for the most relevant text chunks based on a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c55d46-2d32-4c7f-90bf-ad61e6e3f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieved Chunks:\n",
      "1. Past: The Foundation of AI The roots of AI trace back to the mid20th century when researchers began exploring whether machines could mimic human intelligence. Some key milestones include: 1950s: Alan Turing introduced the Turing Test, a method to determine a machine's ability to exhibit humanlike intelligence. 1956: The term Artificial Intelligence was coined at the Dartmouth Conference, marking AIs formal birth. 1960s1980s: Expert systems, which used rulebased approaches to solve problems,\n",
      "\n",
      "2. How Artificial Intelligence is Reshaping the Workforce: The Future of Jobs Introduction Artificial Intelligence AI is no longer a distant conceptit is actively transforming industries, businesses, and the global workforce. While some fear AI will replace jobs, others believe it will create new opportunities and enhance human productivity. So, what does the future of work look like in an AIdriven world? The Impact of AI on Jobs AI is automating repetitive tasks, optimizing workflows, and\n",
      "\n",
      "3. produce unique and stunning visuals, melodies, and literary works. AI helps artists, musicians, and writers by enhancing their creative process. AIgenerated art has been recognized and even auctioned at prestigious events. Arguments Against AI Creativity AI lacks personal experiences, emotions, and subjective intuition. AI relies on existing data and does not create truly new concepts. AI cannot understand the meaning behind its creationsonly humans can. While AI can generate creative outputs,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve_top_k(query, k=3):\n",
    "    \"\"\"Retrieve top-k relevant text chunks based on query\"\"\"\n",
    "    \n",
    "    # Convert query to embedding\n",
    "    query_embedding = embedder.encode([query])\n",
    "    \n",
    "    # Search FAISS index\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Retrieve text chunks\n",
    "    retrieved_texts = [text_chunks[i] for i in indices[0]]\n",
    "    \n",
    "    return retrieved_texts\n",
    "\n",
    "# Test Retrieval\n",
    "query = \"What is artificial intelligence?\"\n",
    "retrieved_chunks = retrieve_top_k(query)\n",
    "\n",
    "print(\" Retrieved Chunks:\")\n",
    "for idx, chunk in enumerate(retrieved_chunks):\n",
    "    print(f\"{idx+1}. {chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ed92d-2b77-4a63-ab06-2a30f05a5a38",
   "metadata": {},
   "source": [
    "### Save FAISS Index for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41bffe97-3a1e-4f63-9875-9abb32ff0be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FAISS Index and Text Chunks saved for future use.\n"
     ]
    }
   ],
   "source": [
    "faiss.write_index(index, \"faiss_index.idx\")\n",
    "\n",
    "# Also, save text chunks for later retrieval\n",
    "with open(\"retrieved_text_chunks.pkl\", \"wb\") as file:\n",
    "    pickle.dump(text_chunks, file)\n",
    "\n",
    "print(\" FAISS Index and Text Chunks saved for future use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143f2fe-c9f5-4fbd-b2ee-7547a4fcd249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
